[Common]
experiment_name : TestTraining
configuration_save_path : ../experiments/${Common:experiment_name}/logs/configs/
# Possible values: train, test
mode : test
[Kicker]
horizon : 1000
# Action space
continuous_act_space : True
multi_discrete_act_space : False
# Observation space
image_obs_space : False
# Episode definition
end_episode_on_struck_goal : True
end_episode_on_conceded_goal : True
reset_goalie_position : True
# Rendering
render_training : False
# Discrete parameters
lateral_bins : 5
angular_bins : 5
# Step frequency
step_frequency : 16

[Algorithm]
policy : MlpPolicy
# See SB3 documentation for available options and train.py for additional implementation requirements
#policy_kwargs : {'net_arch':[64, 64, 64, 64]}
tensorboard_log : ../experiments/${Common:experiment_name}/tensorboard/
#learning_rate: 0.01
#buffer_size : 1000000
#batch_size : 32
#discount_factor : 0.95
#exploration_fraction : 0.4
[Training]
total_timesteps : 4096
tb_log_name : training_run

##########################################################################
################               DEFAULT ARGS               ################
##########################################################################

[Callback]
save_freq : 4096
save_path : ../experiments/${Common:experiment_name}/logs/models/
save_replay_buffer : True
save_vecnormalize : True

[VideoRecording]
video_folder : ../experiments/${Common:experiment_name}/logs/videos/
video_interval : 100000
video_length : 750


[Testing]
eval_seed : 1
test_model_path: models/rl_model_1_1500000_steps.zip
normalized_env_path: model/to/test/env_rms.pkl
num_eval_episodes : 100
