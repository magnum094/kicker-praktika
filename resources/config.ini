[Common]
experiment_name : TestRun
configuration_save_path : ../experiments/${Common:experiment_name}/logs/configs/

[Kicker]
horizon : 1000
# Action space
continuous_act_space : False
multi_discrete_act_space : False
# Observation space
image_obs_space : False
# Episode definition
end_episode_on_struck_goal : True
end_episode_on_conceded_goal : True
reset_goalie_position : True
# Rendering
render_training : False
# Discrete parameters
lateral_bins : 5
angular_bins : 5
# Step frequency
step_frequency : 16

[Algorithm]
policy : MlpPolicy
# See SB3 documentation for available options and train.py for additional implementation requirements
;policy_kwargs : {'net_arch':{'pi':[64, 64], 'vf':[64, 64]}}
tensorboard_log : ../experiments/${Common:experiment_name}/tensorboard/
num_layers : 4
optimizer : Adam
learning_rate: 0.01
buffer_size : 1000000
batch_size : 32
discount_factor : 0.95
exploration_fraction : [0.8, 0.2]
[Training]
total_timesteps : 2000000
tb_log_name : training_run

##########################################################################
################               DEFAULT ARGS               ################
##########################################################################

[Callback]
save_freq : 500000
save_path : ../experiments/${Common:experiment_name}/logs/models/
save_replay_buffer : True
save_vecnormalize : True

[VideoRecording]
video_folder : ../experiments/${Common:experiment_name}/logs/videos/
video_interval : 100000
video_length : 750
